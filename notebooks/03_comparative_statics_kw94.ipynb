{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Static Analysis Keane and Wolpin (1994)\n",
    "\n",
    "### Baseline parametrization\n",
    "\n",
    "In the following we present the key ingredients of the parametrization:\n",
    "\n",
    "- Schooling increases wages by 4% in occupation a (blue collar).\n",
    "- Schooling increases wages by 8% in occupation b (white collar).\n",
    "- Consumption value of schooling of $\\$$5,000.\n",
    "- Once left school, $\\$$15,000 cost of re-enrollment.\n",
    "- Individuals are forward-looking and $\\delta$ = 0.95.\n",
    "- Random shocks are not correlated across alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import respy as rp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from python.auxfunc_parallelizing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "\n",
    "Life-cycle histories of 1,000 individuals for 40 periods are simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = 1000\n",
    "NUM_PERIODS = 40\n",
    "\n",
    "# Load example model and convert parameter and options to model attributes.\n",
    "params, options = rp.get_example_model(\"kw_94_two\", with_data=False)\n",
    "options[\"simulation_agents\"] = NUM_AGENTS\n",
    "options[\"n_periods\"] = NUM_PERIODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_schooling = {\n",
    "    \"blue_collar\": params.loc[(\"wage_a\", \"exp_edu\"), \"value\"],  # occupation \"b\"\n",
    "    \"white_collar\": params.loc[(\"wage_b\", \"exp_edu\"), \"value\"]  # occupation \"a\"\n",
    "}\n",
    "print(ret_schooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_base = rp.get_simulate_func(params, options)\n",
    "df_base = simulate_base(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = {\n",
    "    \"School\": df_base.groupby(\"Identifier\")[\"Experience_Edu\"].max().mean(),\n",
    "    \"White\": df_base.groupby(\"Identifier\")[\"Experience_B\"].max().mean(),  # white collar\n",
    "    \"Blue\": df_base.groupby(\"Identifier\")[\"Experience_A\"].max().mean(),  # blue collar\n",
    "}\n",
    "experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice patterns for Keane and Wolpin (1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "shares = df_base.groupby(\"Period\").Choice.value_counts(normalize=True).unstack()[\n",
    "    [\"edu\", \"b\", \"a\", \"home\"]\n",
    "]\n",
    "labs = [\"School\", \"White\", \"Blue\", \"Home\"]\n",
    "\n",
    "shares.plot.bar(stacked=True, ax=ax, width = 0.8)\n",
    "\n",
    "ax.legend(\n",
    "    labels = labs,\n",
    "    loc = \"upper center\", \n",
    "    bbox_to_anchor=(0.5, 1.15),\n",
    "    ncol = len(labs)\n",
    ")\n",
    "\n",
    "# x-axis options\n",
    "ax.set_xticks(range(0, options[\"n_periods\"], 5))\n",
    "ax.set_xticklabels(range(0, options[\"n_periods\"], 5), rotation=\"horizontal\")\n",
    "\n",
    "# y-axis options\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel(\"Share of individuals\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Statics: Let Ambiguity In!\n",
    "---\n",
    "\n",
    "We study the comparative statics of the model for three ambiguity scenarios. The extent of ambiguity is given by the size of the so-called \"ambiguity-set\", which is in turn governed by the parameter $\\eta$. We will compare three ambiguity scenarios:\n",
    "- risk-only (absent) model $\\eta$ = 0.00\n",
    "- low level of ambiguity $\\eta$ = 0.01\n",
    "- high level of ambiguity $\\eta$ = 0.02\n",
    "\n",
    "*Note:* There is no clear interpretation of what the terms \"low\" and \"high\" mean. At this point we will use them for labelling purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguity_values = {\n",
    "    \"absent\": 0.00,\n",
    "    \"low\": 0.1,\n",
    "    \"high\": 0.2,\n",
    "}\n",
    "\n",
    "ambiguity_labels = list(ambiguity_values.keys())\n",
    "\n",
    "# Initialize containers for the analysis\n",
    "effect_ambiguity_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguity_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Keane and Wolpin (1994) specification and add ambiguity to it. We will build the simulate function based on our parameters. Note that the `simulate` function can be reused because only parameters change in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, options, _ = rp.get_example_model(\"kw_94_two\")\n",
    "options[\"simulation_agents\"] = NUM_AGENTS\n",
    "options[\"n_periods\"] = NUM_PERIODS\n",
    "\n",
    "params.loc[(\"eta\", \"eta\"), \"value\"] = 0.00\n",
    "simulate = rp.get_simulate_func(params, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ambiguity level (absent, low, high) simulate and solve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Parallelizing Try One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "\n",
    "for ambiguity_level in ambiguity_labels:\n",
    "    params, _, _ = rp.get_example_model(\"kw_94_two\")\n",
    "    params.loc[(\"eta\", \"eta\"), :] = ambiguity_values[ambiguity_level]\n",
    "    tasks.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames_ambiguity = distribute_tasks(simulate, tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames_ambiguity = []\n",
    "\n",
    "for ambiguity_level in ambiguity_labels:\n",
    "    params, _, _ = rp.get_example_model(\"kw_94_two\")\n",
    "    params.loc[(\"eta\", \"eta\"), :] = ambiguity_values[ambiguity_level]\n",
    "    simulate = rp.get_simulate_func(params, options)\n",
    "    print(\"Current ambiguity value:\", params.loc[(\"eta\", \"eta\"), \"value\"], \".\")\n",
    "    data_frames_ambiguity.append(simulate(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguity_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Ambiguity Set on average year of experience\n",
    "\n",
    "Assemble the effect of the ambiguity set on the average years an individual spends in each of the four alternatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, ambiguity_level in zip(data_frames_ambiguity, ambiguity_labels):\n",
    "    exp_edu = df.groupby(\"Identifier\")[\"Experience_Edu\"].max().mean()\n",
    "    exp_b = df.groupby(\"Identifier\")[\"Experience_B\"].max().mean()  # white collar\n",
    "    exp_a = df.groupby(\"Identifier\")[\"Experience_A\"].max().mean()  # blue collar\n",
    "    \n",
    "    effect_ambiguity_set[ambiguity_level] = [\n",
    "        exp_edu,\n",
    "        exp_b, \n",
    "        exp_a,\n",
    "        50 - exp_edu - exp_a - exp_b\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_ambiguity_set = pd.DataFrame.from_dict(effect_ambiguity_set, orient=\"index\")\n",
    "df_effect_ambiguity_set.rename(\n",
    "    columns={0: \"School\", 1: \"White\", 2: \"Blue\", 3: \"Home\"}\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course - this crap is simply WRONG\n",
    "\n",
    "We calculate the time spent at home via the difference `Home` = 50 - `Experience_Edu` - `Experience_B` - `Experience_A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 4), sharey=True, sharex=True)\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for df, ax, ambiguity_label in zip(data_frames_ambiguity, axs, ambiguity_labels):\n",
    "    shares = df.groupby(\"Period\").Choice.value_counts(normalize=True).unstack()[\n",
    "        [\"edu\", \"b\", \"a\", \"home\"]\n",
    "    ]\n",
    "\n",
    "    shares.plot.bar(stacked=True, ax=ax, width=0.9, legend=True)\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(\"Share of individuals\")\n",
    "    \n",
    "    ax.set_xticks(range(0, 40, 5))\n",
    "    ax.set_xticklabels(range(0, 40, 5), rotation=\"horizontal\")\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_title(f\"Ambiguity level: {ambiguity_label}\")\n",
    "    \n",
    "# Assmble the legend of the figure    \n",
    "fig.legend(\n",
    "    handles,\n",
    "    labs,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.418, 1),\n",
    "    ncol=4\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Utility Loss\n",
    "\n",
    "For each ambiguity scenario we compute the loss in expected total discounted utility for an individual entering the model. We compare it to the work without any ambiguity at all, referred to \"risk-only\" world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the expected utility under each of the ambiguity settings, we will make use of `shared.aggregate_keane_wolpin_utility`. In particular, we should take the highest flow utility value in each period, and aggregate them through periods, to obtain the expected utility. \n",
    "\n",
    "The expected utility loss is defined as \n",
    "\n",
    "$$ \\text{Expected Utility Loss} \\equiv \\dfrac{ \\text{EU}_{\\eta =0} - \\text{EU}_{\\eta = a} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Statics: Let Ambiguity and Tuition Subsidies In!\n",
    "---\n",
    "\n",
    "We will still consider our three ambiguity scenarios absent, low, and high. However, for each of those scenarios we will compare the effect of a tuition subsidy worth $\\$$1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUITION_SUBSIDIES = [0, 1000]\n",
    "\n",
    "ambiguities = np.repeat(list(ambiguity_values.values()), len(TUITION_SUBSIDIES))\n",
    "tuition_subsidies = len(ambiguity_values) * TUITION_SUBSIDIES\n",
    "\n",
    "effect_ambiguity_set_subsidy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames_ambiguity_subsidies = []\n",
    "\n",
    "for ambiguity_level, tuition_subsidy in zip(ambiguities, tuition_subsidies): \n",
    "    params, _, _ = rp.get_example_model(\"kw_94_two\")\n",
    "    params.loc[(\"nonpec_edu\", \"at_least_twelve_exp_edu\"), \"value\"] += tuition_subsidy\n",
    "    params.loc[(\"eta\", \"eta\"), \"value\"] = ambiguity_level\n",
    "    data_frames_ambiguity_subsidies.append(simulate(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ambiguity_subsidies_zero = [\n",
    "    data_frames_ambiguity_subsidies[2*i] \n",
    "    for i in range(0, len(list(ambiguity_values.values())))\n",
    "]\n",
    "\n",
    "df_ambiguity_subsidies_nonzero = [\n",
    "    data_frames_ambiguity_subsidies[2*i+1] \n",
    "    for i in range(0,len(list(ambiguity_values.values())))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_zero, df, ambiguity_label in zip(\n",
    "    df_ambiguity_subsidies_zero, \n",
    "    df_ambiguity_subsidies_nonzero,\n",
    "    ambiguity_labels):\n",
    "    \n",
    "    exp_edu_zero = df_zero.groupby(\"Identifier\")[\"Experience_Edu\"].max().mean()\n",
    "    exp_b_zero = df_zero.groupby(\"Identifier\")[\"Experience_B\"].max().mean()  # white collar\n",
    "    exp_a_zero = df_zero.groupby(\"Identifier\")[\"Experience_A\"].max().mean()  # blue collar\n",
    "    \n",
    "    exp_edu = df.groupby(\"Identifier\")[\"Experience_Edu\"].max().mean()\n",
    "    exp_b = df.groupby(\"Identifier\")[\"Experience_B\"].max().mean()  # white collar\n",
    "    exp_a = df.groupby(\"Identifier\")[\"Experience_A\"].max().mean()  # blue collar\n",
    "    \n",
    "    effect_ambiguity_set_subsidy[ambiguity_label] = {\n",
    "        \"0\": {\"Edu\":exp_edu, \"White\":exp_b, \"Blue\": exp_a, \"Home\": 50 - exp_edu - exp_a - exp_b},\n",
    "        \"1000\": {\"Edu\": exp_edu_zero, \"White\": exp_b_zero, \"Blue\": exp_a_zero, \"Home\": 50 - exp_edu_zero - exp_a_zero - exp_b_zero}, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_ambiguity_set_subsidy = pd.DataFrame.from_dict(\n",
    "    {(i,j): effect_ambiguity_set_subsidy[i][j] \n",
    "     for i in effect_ambiguity_set_subsidy.keys() \n",
    "     for j in effect_ambiguity_set_subsidy[i].keys()},\n",
    "    orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effect_ambiguity_set_subsidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples for indexing above dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_effect_ambiguity_set_subsidy.loc[(\"absent\", \"1000\"), \"Edu\"])\n",
    "print(df_effect_ambiguity_set_subsidy[[\"Edu\", \"White\"]].loc[\"absent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    len(list(ambiguity_values.values())),  # amount of ambiguity values we are considering\n",
    "    len(TUITION_SUBSIDIES),  # how many tuition subsidies we consider (0 included)\n",
    "    figsize=(10, 12), \n",
    "    sharey=True, \n",
    "    sharex=True\n",
    ")\n",
    "\n",
    "axs = axs.flatten()\n",
    "ambiguities_labels = np.repeat(ambiguity_labels, len(TUITION_SUBSIDIES))\n",
    "\n",
    "for df, ax, ambiguity_label, tuition_subsidy in zip(data_frames_ambiguity_subsidies, axs, ambiguities_labels, tuition_subsidies):\n",
    "    shares = df.groupby(\"Period\").Choice.value_counts(normalize=True).unstack()[\n",
    "        [\"edu\", \"b\", \"a\", \"home\"]\n",
    "    ]\n",
    "\n",
    "    shares.plot.bar(stacked=True, ax=ax, width=0.9, legend=True)\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(\"Share of individuals\")\n",
    "        \n",
    "    ax.set_xticks(range(0, 40, 5))\n",
    "    ax.set_xticklabels(range(0, 40, 5), rotation=\"horizontal\")\n",
    "   \n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()\n",
    "    if tuition_subsidy:\n",
    "        label = f\"Tuition subsidy of {tuition_subsidy:,} USD\"\n",
    "    else:\n",
    "        label = \"No tuition subsidy\"\n",
    "    ax.set_title(f\"Ambiguity-level: {ambiguity_label} \\n {label}\")\n",
    "     \n",
    "fig.legend(\n",
    "    handles,\n",
    "    labs,\n",
    "    bbox_to_anchor=(0.5, 0.95), \n",
    "    borderaxespad=0,\n",
    "    loc=\"lower center\",\n",
    "    ncol=4\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.tight_layout(pad=3.0);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of state variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_base.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "> Keane, M. P. and  Wolpin, K. I. (1994). [The Solution and Estimation of Discrete Choice Dynamic Programming Models by Simulation and Interpolation: Monte Carlo Evidence](https://doi.org/10.2307/2109768). *The Review of Economics and Statistics*, 76(4): 648-672."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
